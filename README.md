This project investigates the application of various statistical and deep learning models to predict the probability distribution of Elon Musk's weekly tweet counts as represented on the Polymarket prediction platform. We utilize a dataset comprising historical tweet engagement metrics, news sentiment scores, and lagged Polymarket probability distributions. Our analysis compares the performance of Linear Regression, Polynomial Regression, Autoregressive Integrated Moving Average (ARIMA), Long Short-Term Memory networks (LSTM), and Transformer networks, evaluated using cross-entropy loss. The results demonstrate that the LSTM model significantly outperforms other approaches, suggesting its effectiveness in capturing the temporal dynamics and probabilistic nature of the prediction target. We further provide predicted probability mass functions for a specific daily and weekly forecast horizon, illustrating the models' varying degrees of confidence and distributional characteristics. Our findings highlight the potential of sequential models for probabilistic forecasting in prediction markets.

Prediction markets, such as Polymarket, offer a unique platform for forecasting future events by aggregating diverse opinions into probabilistic outcomes. This paper explores the efficacy of various statistical and deep learning models in predicting the weekly tweet counts of Elon Musk, a figure known for his prolific and often unpredictable social media activity. Accurately forecasting such activity presents a challenging yet compelling problem, given the potential insights it offers into public sentiment, market behavior, and the dynamics of online discourse. If one were to be able to accurately predict how frequently Musk will tweet, they would be able to profit on Polymarket. This presents the motivation for such a challenge.

Our study leverages a dataset that includes historical tweet engagement metrics, sentiment scores derived from related news articles, and lagged probability distributions from Polymarket to predict future tweet counts. We evaluate a range of models, including traditional linear and polynomial regression, time-series analysis via ARIMA, and sequence modeling with LSTM and Transformer networks. The primary objective is to determine which modeling approach best captures the inherent uncertainty and temporal dependencies in Muskâ€™s tweeting patterns, ultimately providing accurate probabilistic forecasts.

The results highlight several key insights:

* **Sequential models outperform traditional regression approaches.** The LSTM and transformer models outperformed linear and polynomial regression, suggesting that time-series models capable of capturing sequential dependencies are more effective for this problem, especially when modeling temporal trends in Musk's tweeting behavior. This makes sense, as modeling markets typically cannot be accurately captured with linear or polynomial models, as they have underlying nonlinear features with difficult-to-predict metrics.
    
* **LSTM superiority.** The LSTM model achieved the best performance, potentially due to its ability to remember and process long-term temporal dependencies more effectively than the transformer in our configuration. While transformers are powerful, they may require more training data or architectural tuning (e.g., increased context length, more layers) to outperform LSTMs in this relatively small dataset setting. It is interesting that while there were relatively few samples to work with for the LSTM model, it still outperformed the rest.
    
* **Poor performance of ARIMA and polynomial regression.** The ARIMA model's underperformance can likely be attributed to its inability to leverage additional features beyond the lagged target. Similarly, polynomial regression may have overfit the training data and failed to generalize well to the test set.
    
NOTE: AI was used in this project for assistance with debugging, helping organize code, and explain some concepts. All work is our own, following course rules and Yale guidelines.
